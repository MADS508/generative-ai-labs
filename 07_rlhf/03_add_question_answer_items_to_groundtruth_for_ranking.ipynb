{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add items for human feedback\n",
    "\n",
    "![Pipeline](img/generative_ai_pipeline_rlhf_plus.png)\n",
    "\n",
    "![RLHF](img/rlhf_qa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=8100175872, available=3173896192, percent=60.8, used=4640952320, free=164724736, active=659849216, inactive=6969819136, buffers=1105920, cached=3293392896, shared=905216, slab=199868416)\n",
      "*******************************************\n",
      "YOU ARE NOT USING THE CORRECT INSTANCE TYPE\n",
      "PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge \n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "print(notebook_memory)\n",
    "\n",
    "if notebook_memory.total < 32 * 1000 * 1000 * 1000:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Amazon Python SDK clients\n",
    "sagemaker = boto3.client(\"sagemaker\", region)\n",
    "#comprehend = boto3.client(\"comprehend\", region)\n",
    "a2i = boto3.client(\"sagemaker-a2i-runtime\")\n",
    "s3 = boto3.client(\"s3\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the `augmented_ai_flow_definition_arn` Created Previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r augmented_ai_flow_definition_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:550703975190:flow-definition/fd-ranking-a1c4ea3b-1a1f-469d-9673-600e35aac12d\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_flow_definition_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [\n",
    "    {\n",
    "        \"prompt\": \"\"\"\n",
    "            Chris: Hey Antje and Shelbee! Do you want to write a book on generative AI?\n",
    "            Antje: That sounds fun. What do you think, Shelbee?\n",
    "            Shelbee: Of course! Should we title the book, “Generative AI on AWS”?\n",
    "            Chris: Yes!\n",
    "            Antje: Yes!\n",
    "        \"\"\",\n",
    "        \"responses\": [\n",
    "            \"\"\"\n",
    "            Chris, Shelbee, and Antje agree to write a book titled, “Generative AI on AWS”.           \n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris asks Antje and Shelbee if they want to write a book on generative AI. They agree to write the book.\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris asks Antje and Shelbee to write a book. They agree.            \n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            Chris, Antje, and Shelbee decide not to write a book.            \n",
    "            \"\"\"            \n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item: \"{'prompt': '\\n            Chris: Hey Antje and Shelbee! Do you want to write a book on generative AI?\\n            Antje: That sounds fun. What do you think, Shelbee?\\n            Shelbee: Of course! Should we title the book, “Generative AI on AWS”?\\n            Chris: Yes!\\n            Antje: Yes!\\n        ', 'responses': ['\\n            Chris, Shelbee, and Antje agree to write a book titled, “Generative AI on AWS”.           \\n            ', '\\n            Chris asks Antje and Shelbee if they want to write a book on generative AI. They agree to write the book.\\n            ', '\\n            Chris asks Antje and Shelbee to write a book. They agree.            \\n            ', '\\n            Chris, Antje, and Shelbee decide not to write a book.            \\n            ']}\"\n",
      "*** ==> Starting human loop with name: 79ecf947-1407-4ec0-9e39-d93c95208c19  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_loops_started = []\n",
    "\n",
    "for item in items:\n",
    "    print(f'Processing item: \"{item}\"')\n",
    "\n",
    "    humanLoopName = str(uuid.uuid4())\n",
    "    inputContent = {\"taskObject\": item}\n",
    "    start_loop_response = a2i.start_human_loop(\n",
    "        HumanLoopName=humanLoopName,\n",
    "        FlowDefinitionArn=augmented_ai_flow_definition_arn,\n",
    "        HumanLoopInput={\"InputContent\": json.dumps(inputContent)},\n",
    "    )\n",
    "\n",
    "    human_loops_started.append(humanLoopName)\n",
    "\n",
    "    print(f\"*** ==> Starting human loop with name: {humanLoopName}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_loops_started' (list)\n"
     ]
    }
   ],
   "source": [
    "%store human_loops_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 79ecf947-1407-4ec0-9e39-d93c95208c19\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-550703975190/ground-truth-star-rating-results/fd-ranking-a1c4ea3b-1a1f-469d-9673-600e35aac12d/2024/07/05/23/11/51/79ecf947-1407-4ec0-9e39-d93c95208c19/output.json'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wait For Workers to Complete Their Human Loop Tasks\n",
    "\n",
    "Navigate to the link below and login with your email and password that you used when you set up the Private Workforce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r augmented_ai_workteam_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:550703975190:workteam/private-crowd/Lab\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_workteam_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://2l9icwyylz.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _YOU MUST LABEL THE DATA BY CLICKING THE LINK ABOVE BEFORE CONTINUING!!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Labeling\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-start-working.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Label\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-select-label.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loop is Completed\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-finished-task.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Human Loops are Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://2l9icwyylz.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 79ecf947-1407-4ec0-9e39-d93c95208c19\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-550703975190/ground-truth-star-rating-results/fd-ranking-a1c4ea3b-1a1f-469d-9673-600e35aac12d/2024/07/05/23/11/51/79ecf947-1407-4ec0-9e39-d93c95208c19/output.json'}\n",
      "\n",
      "Waiting for HumanLoop to complete.\n",
      "Waiting for HumanLoop to complete.\n",
      "Waiting for HumanLoop to complete.\n",
      "Waiting for HumanLoop to complete.\n",
      "Waiting for HumanLoop to complete.\n",
      "Completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "    while resp[\"HumanLoopStatus\"] != \"Completed\":\n",
    "        print(f\"Waiting for HumanLoop to complete.\")\n",
    "        time.sleep(10)\n",
    "        resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)\n",
    "        print(f\"Completed!\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# View Human Labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the work is complete, Amazon GroundTruth stores the results in the specified S3 bucket and sends a Cloudwatch Event.  Here is a sample item labeled with GroundTruth in `jsonlines` format:\n",
    "```\n",
    "{\n",
    " \"inputContent\": {\"taskObject\": {\n",
    "                         \"prompt\": \"Who is Angela Merkel's favorite President of the United States?\",\n",
    "                         \"responses\": [\"George Clinton\", \"Barack Obama\"]}\n",
    "                 },\n",
    " \"humanAnswers\": [{\"answerContent\": {\n",
    "                        \"ranking_1\": \"1\", # ranking for 1st response (1 is High)\n",
    "                        \"ranking_2\": \"2\"  # ranking for 2nd response (2 is Low)\n",
    "                 }}]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare human-labeled data for RL/PPO training\n",
    "Retrieve from GrountTruth and convert to a binary reward (-1, 1) for all rankings as follows:\n",
    "\n",
    "From this:\n",
    "```\n",
    "prompt                                                              response           ranking\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     George Clinton     1   # High\n",
    "Who is Angela Merkel's favorite President of the United States?     Barack Obama       2   # Low\n",
    "```\n",
    "\n",
    "To this:\n",
    "```\n",
    "prompt                                                              response           reward\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     George Clinton     0   # Low reward\n",
    "Who is Angela Merkel's favorite President of the United States?     Barack Obama       1   # High reward\n",
    "```\n",
    "\n",
    "To this:\n",
    "```\n",
    "prompt                                                              response                               highest_ranked_response\n",
    "\n",
    "Who is Angela Merkel's favorite President of the United States?     [\"George Clinton\", \"Barack Obama\"]     [0, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# _Note:  If nothing is showing up below, you need to return to finish the previous notebook by labeling the data in Ground Truth!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "human_feedback_items = []\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    human_feedback_s3_uri = resp[\"HumanLoopOutput\"][\"OutputS3Uri\"]\n",
    "    split_string = re.split(\"s3://\" + bucket + \"/\", resp[\"HumanLoopOutput\"][\"OutputS3Uri\"])\n",
    "    key = split_string[1]\n",
    "    \n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "    json_output = json.loads(content)\n",
    "\n",
    "    prompt = json_output[\"inputContent\"]['taskObject']['prompt']\n",
    "    responses = json_output[\"inputContent\"]['taskObject']['responses']\n",
    "    response_1_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_1_ranking']\n",
    "    response_2_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_2_ranking']\n",
    "    \n",
    "    human_feedback_item_1 = (prompt, responses[0], response_1_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_1)\n",
    "    human_feedback_item_2 = (prompt, responses[1], response_2_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris asks Antje and Shelbee if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "1  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...       1  \n",
       "1  \\n            Chris asks Antje and Shelbee if ...       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items = pd.DataFrame(human_feedback_items, columns=['prompt', 'response', 'ranking'])\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert ranking into 0 or 1 reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris asks Antje and Shelbee if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "1  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...       1  \n",
       "1  \\n            Chris asks Antje and Shelbee if ...       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rankings = 2\n",
    "df_human_feedback_items['response'] = df_human_feedback_items['response'].apply(lambda response: str(response))\n",
    "df_human_feedback_items['ranking'] = df_human_feedback_items['ranking'].apply(lambda ranking: str(abs(int(ranking) - num_rankings)))\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>\\n            Chris, Shelbee, and Antje agree ...</td>\n",
       "      <td>1,1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  \\n            Chris, Shelbee, and Antje agree ...     1,1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt = df_human_feedback_items.groupby('prompt', as_index=False).agg({'prompt' : 'first', 'response' : ','.join, 'ranking' : ','.join})\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            Chris: Hey Antje and Shelbee! Do...</td>\n",
       "      <td>[\\n            Chris,  Shelbee,  and Antje agr...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\n            Chris: Hey Antje and Shelbee! Do...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  [\\n            Chris,  Shelbee,  and Antje agr...  [1, 1]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt['response'] = df_human_feedback_items_grouped_by_prompt['response'].apply(lambda response: [s for s in response.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt['ranking'] = df_human_feedback_items_grouped_by_prompt['ranking'].apply(lambda ranking: [int(s) for s in ranking.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'ranking'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create Dataset objects (Arrow PyTables) from Pandas dataframes\n",
    "human_feedback_dataset = Dataset.from_pandas(df_human_feedback_items_grouped_by_prompt)\n",
    "human_feedback_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_feedback_dataset' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "%store human_feedback_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _YOU MUST LABEL THE DATA BY CLICKING THE LINK ABOVE BEFORE CONTINUING!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "\n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "\n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
